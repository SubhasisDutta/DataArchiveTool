<?xml version="1.0"?>
<conf>
	<source> <!-- This is the details of the table from which data needs to be archived -->
		<type>CASSANDRA</type>
		<clusters>
			<cluster>127.0.0.1</cluster>
		</clusters>
		<port>9042</port>
		<dataSource>
			<keyspace>testkeyspace</keyspace> <!-- Tool  assumes that the keyspace is already present in Cassandra -->
			<table>tweets_new</table>			
			<selectlimit>10</selectlimit>
			<batchlimit>20</batchlimit>
		</dataSource>				
	</source>	
	<temporarydump><!-- This is the details of a temporary table which is used during archiving. This able should have the same schema as the source table. -->
		<type>CASSANDRA</type>
		<clusters>
			<cluster>127.0.0.1</cluster>
		</clusters>
		<port>9042</port>
		<dataSource>
			<keyspace>testkeyspace</keyspace> <!-- Tool  assumes that the keyspace  & table is already present is already present in Cassandra -->
			<table>tweets_new_temp</table>
			<batchlimit>10</batchlimit>
		</dataSource>				
	</temporarydump>
	<condition>
		<!-- this column must be in the partition key else cassandra wont be able to perform select operation -->
		<columnname>posteddate</columnname>
		<operator>LESS</operator><!-- EQUAL, LESS, GREATER, LESS_EQUAL, GRATER_EQUAL -->
		<valuetype>DATETIME</valuetype> <!-- DATETIME, INTEGER, STRING, BOOLEAN -->
		<value>90:DAYS</value> <!-- 100:HOURS/DAYS(This special syntax which is calculated from current date minus x days),50, "ABC", True/False  -->
	</condition>
	
	<archive>
		<format>CSV</format>
		<mode>FILE</mode>
		<compression>BZ2</compression>
		<location></location>		
	</archive>
	
	<transfer>		
		<connection destination="AWS_S3">
			<AccessKey>AKIAIYS2IMXPCCIQR5OQ</AccessKey>
			<SecretAccessKey>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</SecretAccessKey>
			<Bucket>mybucketserendiotest</Bucket>
		</connection>
	</transfer>
</conf>